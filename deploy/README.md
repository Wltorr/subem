# Adobe Premiere Pro AI AltyazÄ± Eklentisi - Deployment

Bu dizin, Adobe Premiere Pro AI AltyazÄ± Eklentisini farklÄ± ortamlarda Ã§alÄ±ÅŸtÄ±rmak iÃ§in gerekli dosyalarÄ± iÃ§erir.

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Windows (Ã–nerilen)
```bash
# HÄ±zlÄ± kurulum scripti
quick-deploy.bat
```

### Docker ile
```bash
# Docker Compose ile baÅŸlat
docker-compose up -d

# LoglarÄ± izle
docker-compose logs -f

# Durdur
docker-compose down
```

### Manuel Kurulum
```bash
# Backend dizinine git
cd backend

# Virtual environment oluÅŸtur
python -m venv venv

# Virtual environment aktifleÅŸtir
# Windows
venv\Scripts\activate.bat
# macOS/Linux
source venv/bin/activate

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# UygulamayÄ± baÅŸlat
python run.py
```

## ğŸ“‹ Gereksinimler

### Sistem Gereksinimleri
- **Python**: 3.8 veya Ã¼zeri
- **FFmpeg**: Ses/video iÅŸleme iÃ§in
- **RAM**: En az 4GB (Whisper modeli iÃ§in)
- **Disk**: En az 2GB boÅŸ alan

### Python Paketleri
- Flask 3.0.0+
- OpenAI Whisper 20231117+
- Faster Whisper 0.10.0+
- PyTorch 2.1.2+
- NumPy 1.26.2+

## ğŸ”§ YapÄ±landÄ±rma

### Environment Variables
```bash
# Whisper model seÃ§imi
WHISPER_MODEL=base          # tiny, base, small, medium, large
USE_FASTER_WHISPER=true     # true/false
DEBUG=true                  # true/false
PORT=5000                   # Port numarasÄ±
```

### Whisper Modelleri
| Model | Boyut | HÄ±z | DoÄŸruluk | Ã–nerilen |
|-------|-------|-----|----------|----------|
| tiny  | ~39 MB | Ã‡ok HÄ±zlÄ± | DÃ¼ÅŸÃ¼k | Test |
| base  | ~74 MB | HÄ±zlÄ± | Ä°yi | **Ã–nerilen** |
| small | ~244 MB | Orta | Ä°yi | Kaliteli |
| medium| ~769 MB | YavaÅŸ | Ã‡ok Ä°yi | Profesyonel |
| large | ~1550 MB | Ã‡ok YavaÅŸ | En Ä°yi | En yÃ¼ksek kalite |

## ğŸ³ Docker Deployment

### Docker Compose
```yaml
version: '3.8'
services:
  ai-subtitles:
    build: .
    ports:
      - "5000:5000"
    environment:
      - WHISPER_MODEL=base
      - USE_FASTER_WHISPER=true
      - DEBUG=false
      - PORT=5000
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    volumes:
      - ./models:/root/.cache/whisper
```

### Docker Build
```bash
# Image oluÅŸtur
docker build -t ai-subtitles .

# Container Ã§alÄ±ÅŸtÄ±r
docker run -d -p 5000:5000 --name ai-subtitles ai-subtitles

# LoglarÄ± izle
docker logs -f ai-subtitles

# Container durdur
docker stop ai-subtitles
```

## ğŸŒ Production Deployment

### Nginx Reverse Proxy
```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://localhost:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

### Systemd Service
```ini
[Unit]
Description=AI Subtitles Backend
After=network.target

[Service]
Type=simple
User=www-data
WorkingDirectory=/path/to/backend
Environment=PATH=/path/to/backend/venv/bin
ExecStart=/path/to/backend/venv/bin/python run.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

## ğŸ” Monitoring & Health Checks

### Health Check Endpoint
```bash
curl http://localhost:5000/health
```

### Response Format
```json
{
  "status": "healthy",
  "model": "base",
  "faster_whisper": true,
  "model_status": "loaded"
}
```

### Log Monitoring
```bash
# Real-time logs
tail -f backend/app.log

# Docker logs
docker-compose logs -f ai-subtitles

# System logs
journalctl -u ai-subtitles -f
```

## ğŸ› ï¸ Troubleshooting

### Common Issues

#### Model Loading Error
```bash
# Model cache temizle
rm -rf ~/.cache/whisper

# Manuel model indirme
python -c "import whisper; whisper.load_model('base')"
```

#### Memory Issues
```bash
# Daha kÃ¼Ã§Ã¼k model kullan
export WHISPER_MODEL=tiny

# Faster Whisper kullan
export USE_FASTER_WHISPER=true
```

#### FFmpeg Error
```bash
# FFmpeg kurulum kontrolÃ¼
ffmpeg -version

# PATH kontrolÃ¼
which ffmpeg
```

#### Port Already in Use
```bash
# Port kullanÄ±mÄ±nÄ± kontrol et
netstat -tulpn | grep :5000

# FarklÄ± port kullan
export PORT=5001
```

### Performance Optimization

#### Whisper Model Selection
```bash
# HÄ±zlÄ± iÅŸlem iÃ§in
export WHISPER_MODEL=tiny
export USE_FASTER_WHISPER=true

# Kaliteli iÅŸlem iÃ§in
export WHISPER_MODEL=base
export USE_FASTER_WHISPER=true
```

#### System Resources
```bash
# CPU kullanÄ±mÄ±
htop

# Memory kullanÄ±mÄ±
free -h

# Disk kullanÄ±mÄ±
df -h
```

## ğŸ“Š Performance Metrics

### Response Times
- **Health Check**: < 100ms
- **Model Info**: < 200ms
- **Transcribe (tiny)**: 2-5 saniye
- **Transcribe (base)**: 5-15 saniye
- **Transcribe (small)**: 15-30 saniye

### Resource Usage
- **Memory**: 500MB - 2GB (model boyutuna gÃ¶re)
- **CPU**: %20-80 (iÅŸlem yoÄŸunluÄŸuna gÃ¶re)
- **Disk**: 100MB - 1GB (model cache)

## ğŸ”’ Security Considerations

### Firewall Configuration
```bash
# Sadece gerekli portlarÄ± aÃ§
sudo ufw allow 5000/tcp

# IP kÄ±sÄ±tlamasÄ±
sudo ufw allow from 192.168.1.0/24 to any port 5000
```

### Environment Security
```bash
# Hassas bilgileri environment variables olarak sakla
export OPENAI_API_KEY="your-api-key"

# Production'da debug modunu kapat
export DEBUG=false
```

## ğŸ“ Support

Sorunlar iÃ§in:
1. GitHub Issues kullanÄ±n
2. Log dosyalarÄ±nÄ± kontrol edin
3. Health check endpoint'ini test edin
4. System resources'larÄ± kontrol edin

---

**Not**: Bu deployment guide sÃ¼rekli gÃ¼ncellenmektedir. En gÃ¼ncel bilgiler iÃ§in GitHub repository'yi kontrol edin.
